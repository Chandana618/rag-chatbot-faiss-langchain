ğŸ“„ RAG-based Document Chatbot.

A Retrieval-Augmented Generation (RAG) chatbot that allows users to ask questions from their own PDF documents using semantic search and a large language model. The system retrieves relevant document chunks using vector similarity and generates accurate, context-grounded answers through an interactive Streamlit interface.

ğŸš€ Features

ğŸ“‘ Upload and query custom PDF documents

âœ‚ï¸ Intelligent text chunking for better context retrieval

ğŸ” Semantic search using vector embeddings

âš¡ Fast similarity search with FAISS

ğŸ¤– LLM-powered answer generation (Groq API)

ğŸ–¥ï¸ Interactive web UI built with Streamlit

ğŸ”‘ No OpenAI API key required

ğŸ§  How It Works (RAG Pipeline)

Document Ingestion
PDF files are loaded from the documents/ directory.

Text Splitting
Documents are split into overlapping chunks to preserve context.

Vector Embeddings
Each chunk is converted into embeddings using a Hugging Face sentence transformer.

Vector Store (FAISS)
Embeddings are stored in FAISS for efficient similarity search.

Retrieval
The most relevant document chunks are retrieved for a given user query.

Generation
A Large Language Model generates answers strictly based on the retrieved context.

ğŸ›  Tech Stack

Programming Language: Python

Framework: LangChain

Vector Database: FAISS

Embeddings: Hugging Face Sentence Transformers

LLM Provider: Groq

Frontend: Streamlit

ğŸ“‚ Project Structure
rag-chatbot-faiss-langchain/
â”‚
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ documents/             # Folder containing PDF files
â”œâ”€â”€ README.md              # Project documentation
â””â”€â”€ .gitignore
